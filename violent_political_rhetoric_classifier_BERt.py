# -*- coding: utf-8 -*-
"""violent_political_rhetoric_classifier_BERT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bxpL7dTWVfkqc9XimB-S0ribh-_P_vkA

**1. Install libararies**
"""

from google.colab import drive
drive.mount("/content/drive")

!pip install torch torchvision
!pip install transformers==2.10.0
!pip install seqeval
!pip install tensorboardx
!pip install simpletransformers==0.9.1

"""**2. Import libraries**"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import pandas as pd
import numpy as np

import gc
import requests
import os

from simpletransformers.classification import ClassificationModel
from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, recall_score, precision_score
from scipy.special import softmax

import torch
print("Cuda available" if torch.cuda.is_available() is True else "CPU")
print("PyTorch version: ", torch.__version__)

"""**3. Download the data into PD DataFrame**"""

url= "https://raw.githubusercontent.com/taegyoon-kim/Dissertation-Essay-1/master/training_sep21.csv"

df = pd.read_csv(url, error_bad_lines=False)
df['text'] = df['status_final_text']
df['threat'] = df['final_binary'].astype(float)
df = df[['text','threat']]

df = df.sample(frac=1).reset_index(drop=True)

"""**4. Performance metrics**"""

def report_results(A, B):
    A_name = A.name
    B_name = B.name
    
    df = pd.DataFrame({'A':A,
                       'B':B})
    df = df.dropna()
    A = df['A']
    B = df['B']
    
    acc = accuracy_score(B, A)
    f1 = f1_score(B, A)
    prec = precision_score(B, A)
    rec = recall_score(B, A)
    ROC = roc_auc_score(B, A)
    
    print('Candidate: '+A_name+' | Ground Truth: '+B_name+'\n')
    print('accuracy: %0.4f \nprecision: %0.4f \nrecall: %0.4f \nF1 score: %0.4f \nROC AUC: %0.4f \n' % (acc, prec, rec, f1, ROC))

    performance = [prec, rec, f1, ROC, acc]

    return performance

"""**5. Train and Test (5-fold CV)**"""

args = {
   'output_dir': 'outputs/',
   'cache_dir': 'cache/',

   'fp16': False,
   'fp16_opt_level': 'O1',
   'max_seq_length': 250,
   'train_batch_size': 8,
   'eval_batch_size': 8,
   'gradient_accumulation_steps': 1,
   'num_train_epochs': 2,
   'weight_decay': 0,
   'learning_rate': 4e-5,
   'adam_epsilon': 1e-8,
   'warmup_ratio': 0.06,
   'warmup_steps': 0,
   'max_grad_norm': 1.0,

   'logging_steps': 50,
   'evaluate_during_training': False,
   'save_steps': 2000,
   'eval_all_checkpoints': True,
   'use_tensorboard': True,

   'overwrite_output_dir': True,
   'reprocess_input_data': True   
}

from sklearn.model_selection import KFold
n = 5
kf = KFold(n_splits = n, random_state = 777, shuffle = True)

for train_index, val_index in kf.split(df):
  # splitting Dataframe (dataset not included)
    train_df = df.iloc[train_index]
    val_df = df.iloc[val_index]
  # Defining Model
    model = ClassificationModel('bert', 'bert-base-uncased', args = args)
  # train the model
    model.train_model(train_df)
  # validate the model 
    #result, model_outputs, wrong_predictions = model.eval_model(val_df)
    #val_df['BERT_threat'] = np.argmax(model_outputs, axis = 1)
    predictions, raw_outputs = model.predict(val_df['text'])
    probabilities = softmax(raw_outputs, axis=1)
    val_df['BERT_threat_900'] = np.where(probabilities[:,1] >= 0.9, 1, 0)
    val_df['BERT_threat_925'] = np.where(probabilities[:,1] >= 0.925, 1, 0)
    val_df['BERT_threat_950'] = np.where(probabilities[:,1] >= 0.95, 1, 0)
  # performance
    performance_900 = report_results(val_df['BERT_threat_900'], val_df['threat'])
    performance_925 = report_results(val_df['BERT_threat_925'], val_df['threat'])
    performance_950 = report_results(val_df['BERT_threat_950'], val_df['threat'])
    print(performance_900)
    print(performance_925)
    print(performance_950)